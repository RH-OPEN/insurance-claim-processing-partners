= Pipeline for processing claims
include::_attributes.adoc[]

== パイプラインは何をしますか?
Web アプリがデプロイされたので、まだ処理されていないクレームがあることがわかります。 もちろん、この処理を実行したいのですが、完全に自動化できればさらに良いでしょう!

そのためには、サニティ チェック パイプラインのように、アドホックで実行することもスケジュールで実行することもできるパイプラインを使用します。

このパイプラインは、自動的にトリガーできる ArgoCD または Tekton パイプラインを作成するための良い出発点でもあります。

パイプラインには LLM にアクセスするタスクがあり、LLM のバックエンドでは GPU ではなく CPU を使用しているため、これらのタスクはそれぞれ少なくとも 2 ～ 4 分かかります。パイプライン全体の実行時間は 8 ～ 10 分になる可能性があるため、パイプラインの実行中に LLM ポッド ログ (管理者ユーザーとして) とパイプライン実行およびタスク ログ (ユーザー 1 として) を表示できます。

== パイプラインの内容

`insurance-claim-processing-partners/lab-materials/05/05-05` に移動すると、さまざまなファイルが表示されます。+

今回は、**パイプライン** の **yaml 定義** である `process_claims.yaml` を使用して請求を処理します。+

パイプラインの主なファイルとその機能は次のとおりです:

* *get_claims* - データベースに接続し、未処理の請求を取得して、ファイル `claims.json` を通じて他のタスクに渡されるリストに追加します。
* 次のスクリプトは、処理する必要があるすべての請求を調べ、テキストの本文全体を使用して重要な機能を見つけ、結果をデータベースにプッシュします:
** *get_location* - Finds the location of the accident.
** *get_accident_time* - Finds the time of the accident.
** *summarize_text* - Makes a short summary of the text.
** *get_sentiment* - Gets the sentiment of the text.
* *detect_objects* - Downloads the images of the claim and uses the served object-detection model to classify the damages in the image.

NOTE: フォルダーには、参照用に Elyra バージョンのパイプライン (`process_claims.pipeline`) が残っていますが、VSCode から実際に使用することはできません。VSCode は、まだ使用すべき環境です。

== 新しい PVC を作成する

パイプラインを実行する前に、中間ファイルと結果を格納するために使用する PVC を作成する必要があります。 +
OpenShift コンソールに移動し、[**ストレージ**]/[**Storage**] -> [PersistentVolumeClaims] に移動します。

[.bordershadow]
image::05/05-PVC.png[PVC に移動]

正しいプロジェクト (ユーザー名) にいることを確認してから、[**PersistentVolumeClaimの作成**]/[**Create PersistentVolumeClaim**] を押します。

[.bordershadow]
image::05/05-create-pvc.png[PVC を作成]

* 次の設定を使用します。
** StorageClass:
[.lines_space]
[.console-input]
[source, text]
[subs=attributes+]
ocs-storagecluster-cephfs
** PersistentVolumeClaim name:
[.lines_space]
[.console-input]
[source, text]
[subs=attributes+]
processing-pipeline-storage
** Access mode:
[.lines_space]
[.console-input]
[source, text]
[subs=attributes+]
Shared access (RWX)
** Size:
[.lines_space]
[.console-input]
[source, text]
[subs=attributes+]
1 GiB

[.bordershadow]
image::05/05-PVC-settings.png[PVC settings]

次に、[**作成済み**]/[**Create**] を押します。

== パイプラインを実行する
パイプラインを実行するには、まず「process_claims.yaml」ファイルをローカルにダウンロードします。 +
次に、データ サイエンス プロジェクトの *Pipelines* タブに移動して、[**Import pipeline**] を押します。

[.bordershadow]
image::05/05-import-pipeline-button.png[パイプラインのインポート]

次に、ドラッグ アンド ドロップするか、[**Upload**] ボタンを使用して、process_claims.yaml ファイルをアップロードします。次に、パイプラインに「Process Claims Pipeline」などの適切な名前を付けます。 +
その後、次のようになります。

[.bordershadow]
image::05/05-imported-pipeline.png[インポートされたパイプライン]

[**Import pipeline**] を押すと、パイプラインの下にポップアップ表示されます。

次に、右側の設定に移動して [**Create run**] を押し、追加したパイプラインの新しい実行を作成します。パイプラインの実行は合計で 8 ～ 10 分かかる可能性があるため、パイプラインの実行中に、LLM ポッド ログ (管理者ユーザーとして) とパイプライン実行およびタスク ログ (ユーザー 1 として) を表示できます。OpenShiftAI UI を表示できます。

[.bordershadow]
image::05/05-create-run.png[create run]

* 次の設定を使用します。
** Name:
[.lines_space]
[.console-input]
[source, text]
[subs=attributes+]
Process Claim Run
** Run type:
[.lines_space]
[.console-input]
[source, text]
[subs=attributes+]
Run once immediately after creation
** claim_id:
[.lines_space]
[.console-input]
[source, text]
[subs=attributes+]
3
** detection_endpoint:
[.lines_space]
[.console-input]
[source, text]
[subs=attributes+]
http://modelmesh-serving.{user}:8008

これは、ワークショップで以前に使用したオブジェクト検出エンドポイントへのルートと同じです。 +
完了すると、次のようになります。

各タスクの完了後にエンドポイントを更新して、クレーム 3 の出力の変化を表示できます。

[.bordershadow]
image::05/05-run-settings-create-pipeline.png[実行設定]

*claim_id* を変更すると、処理するクレームを変更できます。0 に設定すると、未処理のクレームがすべて処理されます。

[**作成済み**]/[**Create**] を押して、実行を確認します。

== 結果を確認する

パイプラインの実行は CPU で行われ、LLM にはもう少し時間がかかるため、理論に関する次のセクションに進み、次のステップについて話し合い、6 ～ 10 分後にこのパイプラインの実行結果に戻って、アプリの Web UI を更新してください。
パイプラインの実行が完了したら、アプリに移動してクレームを確認できます。 +
長い本文だけでなく、概要、場所フィールド、事故時間フィールド、感情フィールドが表示されます。 +
また、損傷箇所に境界ボックスがある新しい画像があることもわかります。
